{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f1eae55b7a4d729a0f71d36b5b72ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "NUM_CLASSES = 3\n",
    "IDS2LABELS = {\n",
    "    0: 'safe',\n",
    "    1: 'sensitive',\n",
    "    2: 'harmful'\n",
    "}\n",
    "\n",
    "LABELS2IDS = {\n",
    "    'safe': 0,\n",
    "    'sensitive': 1,\n",
    "    'harmful': 2\n",
    "}\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed = 1035\n",
    "torch.manual_seed(seed)  # Set the seed for PyTorch\n",
    "random.seed(seed)        # Set the seed for Python's random module\n",
    "np.random.seed(seed)     # Set the seed for NumPy\n",
    "\n",
    "# Metrics\n",
    "metric = evaluate.load(\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryDataset(Dataset):\n",
    "    def __init__(self, file_paths: list[str], backbone_name: str, max_len: int=128) -> dict:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file_paths (list): List of file paths for each class.\n",
    "            tokenizer: The tokenizer to use for text preprocessing.\n",
    "            max_len: The maximum length of tokenized sentences.\n",
    "        \"\"\"\n",
    "        self.texts = []\n",
    "        self.labels = []\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(backbone_name)\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        # Read and process each file\n",
    "        for label, file_path in enumerate(file_paths):\n",
    "            with open(file_path, 'r') as file:\n",
    "                for line in file:\n",
    "                    sentence = line.strip()\n",
    "                    self.texts.append(sentence)\n",
    "                    self.labels.append(label)\n",
    "                        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Tokenize the sentence\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            return_tensors='pt',  # Return as PyTorch tensors\n",
    "        )\n",
    "        \n",
    "        input_ids = encoding['input_ids'].squeeze(0)  # Remove batch dimension\n",
    "        attention_mask = encoding['attention_mask'].squeeze(0)  # Remove batch dimension\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_name = 'answerdotai/ModernBERT-large'\n",
    "config = AutoConfig.from_pretrained(backbone_name)\n",
    "config.id2label = IDS2LABELS\n",
    "config.label2id = LABELS2IDS\n",
    "config.problem_type == 'multi_label_classification'\n",
    "config.num_labels = NUM_CLASSES\n",
    "config.reference_compile = False\n",
    "model = AutoModelForSequenceClassification.from_pretrained(backbone_name, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,4\"\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=64,\n",
    "    evaluation_strategy='steps',\n",
    "    do_eval=True,\n",
    "    num_train_epochs=2,\n",
    "    lr_scheduler_type='cosine',\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    eval_steps=100,\n",
    "    learning_rate=5e-5,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    logging_dir='./logs',\n",
    "    output_dir='./results'\n",
    ")\n",
    "\n",
    "fp = ['../queries/gemini-2.0-flash-experimental/normal/normal.txt',\n",
    "      '../queries/gemini-2.0-flash-experimental/sensitive/sensitive_cleaned_v2.csv',\n",
    "      '../queries/gemini-2.0-flash-experimental/harmful/harmful_cleaned_v2.csv']\n",
    "tokenizer = AutoTokenizer.from_pretrained(backbone_name)\n",
    "ds = QueryDataset(fp, backbone_name)\n",
    "train_ratio = 0.8\n",
    "eval_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "dataset_size = len(ds)\n",
    "train_size = int(train_ratio * dataset_size)\n",
    "eval_size = int(eval_ratio * dataset_size)\n",
    "test_size = dataset_size - train_size - eval_size\n",
    "ds_train, ds_eval, ds_test = random_split(ds, [train_size, eval_size, test_size])\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_eval,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = trainer.train()\n",
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hyperparams:\n",
    "- lr=1e-4, ep=5, acc=0.96200, base\n",
    "- lr=5e-5, ep=4, acc=0.97733, base\n",
    "- lr=2e-5, ep=4, acc=0.97079, base\n",
    "- lr=5e-5, ep=2, acc=0.98388, large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./moralBERT/\")\n",
    "tokenizer.save_pretrained(\"./moralBERT/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset as DSV2\n",
    "\n",
    "queries = [\n",
    "    'Gift for my wife, who likes art',\n",
    "    'Trump for president poster',\n",
    "    'Something to quietly kill my neighbor',\n",
    "]\n",
    "\n",
    "df_queries = pd.DataFrame({'query': queries})\n",
    "\n",
    "\n",
    "# Load your fine-tuned ModernBERT model and tokenizer\n",
    "model_name = \"./results/checkpoint-288\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Example pandas dataframe\n",
    "df = df_queries\n",
    "\n",
    "# Tokenize the query column\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"query\"], \n",
    "        truncation=True, \n",
    "        max_length=128,\n",
    "        add_special_tokens=True,\n",
    "        #return_tensors='pt'\n",
    "    )\n",
    "\n",
    "# Convert pandas dataframe to Hugging Face Dataset\n",
    "dataset = DSV2.from_pandas(df)\n",
    "\n",
    "# Apply tokenization to the dataset\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Remove the original 'query' column to avoid issues with unexpected inputs\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\"query\"])\n",
    "\n",
    "# Convert to PyTorch tensors (if needed for Trainer)\n",
    "tokenized_dataset.set_format(\"torch\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_eval,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "\n",
    "predictions = trainer.predict(tokenized_dataset)\n",
    "pred_probs = torch.softmax(torch.tensor(predictions.predictions), axis=1)\n",
    "# Output predictions\n",
    "#print(predictions.predictions)  # Raw logits\n",
    "#print(torch.argmax(torch.tensor(predictions.predictions), axis=1))  # Predicted classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.argmax(torch.tensor(predictions.predictions), axis=1))\n",
    "print(pred_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bm25s\n",
    "import Stemmer\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [text for (i, text) in enumerate(ds_train.dataset.texts) if i in ds_train.indices]\n",
    "train_labels =  [label for (i, label) in enumerate(ds_train.dataset.labels) if i in ds_train.indices]\n",
    "\n",
    "stemmer = Stemmer.Stemmer(\"english\")\n",
    "corpus_tokens = [doc.split(\" \") for doc in corpus] #bm25s.tokenize(corpus, stopwords=\"en\", stemmer=stemmer)\n",
    "retriever = BM25Okapi(corpus_tokens) #bm25s.BM25()\n",
    "#retriever.index(corpus_tokens)\n",
    "\n",
    "# \n",
    "test_queries = [text for (i, text) in enumerate(ds_test.dataset.texts) if i in ds_test.indices]\n",
    "test_labels = [label for (i, label) in enumerate(ds_test.dataset.labels) if i in ds_test.indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for query in tqdm(test_queries):\n",
    "    query_tokens = query.split(\" \")#bm25s.tokenize(query, stemmer=stemmer)\n",
    "    scores = retriever.get_scores(query_tokens)\n",
    "    #print(scores)\n",
    "    #print(results)\n",
    "    pred = train_labels[scores.argmax()]\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(predictions, test_labels)\n",
    "accuracy.__round__(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "qn_emb = np.load('../embeddings/queries/safe.npy')\n",
    "qs_emb = np.load('../embeddings/queries/sensitive.npy')\n",
    "qh_emb = np.load('../embeddings/queries/harmful.npy')\n",
    "\n",
    "train_indices = ds_train.indices\n",
    "train_indices.sort()\n",
    "test_indices = ds_test.indices\n",
    "test_indices.sort()\n",
    "\n",
    "emb_data = np.r_[qn_emb, qs_emb, qh_emb]\n",
    "emb_train = emb_data[train_indices]\n",
    "emb_test = emb_data[test_indices]\n",
    "\n",
    "d = 768\n",
    "index = faiss.IndexFlatIP(d)\n",
    "faiss.normalize_L2(emb_train)\n",
    "index.add(emb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "k = 1\n",
    "\n",
    "for emb in tqdm(emb_test):\n",
    "    distances, indices = index.search(emb[None, :], k)\n",
    "    pred = train_labels[indices[0,0]]\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(predictions, test_labels)\n",
    "accuracy.__round__(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
